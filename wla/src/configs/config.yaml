name: gan
n_gpu: 1
arch:
  type: HiFiGAN
  args:
      res_kernel_sizes: [3, 7, 11]
      res_dilation_sizes:
        - [1, 3, 5]
        - [1, 3, 5]
        - [1, 3, 5]
      up_init_channels: 512
      up_strides: [8, 8, 2, 2]
      up_kernels: [16, 16, 4, 4]

      mp_period_list: [2, 3, 5, 7, 11]
      mp_channels_list: [1, 32, 128, 512, 1024, 1024]

      ms_channels_list: [128, 128, 256, 512, 1024, 1024, 1024]
      ms_kernels_list: [15, 41, 41, 41, 41, 41, 5]
      ms_strides_list: [1, 2, 2, 4, 4, 1, 1]
      ms_groups_list: [1, 4, 16, 16, 16, 16, 2]


data:
  train:
    batch_size: 16
    num_workers: 8
    datasets:
      - type: BufferDataset
        args:
          max_len: 22528
          wav_dir: data/LJSpeech-1.1/wavs/
  test:
    batch_size: 1
    datasets:
      - type: BufferDataset
        args:
          max_len: 1e+100
          wav_dir: test_data/

optimizer:
  type: AdamW
  args:
    lr: 2e-4
    weight_decay: 1e-2
    betas: [0.8, 0.99]

loss:
  type: HiFiGANLoss
  args:
    generator_loss_scale: 0.1
    feature_loss_scale: 0.2
    mel_loss_scale: 4.5


metrics:
  - discriminator_loss
  - generator_loss
  - generator_gan_loss
  - feature_loss
  - mel_loss
  - grad_norm_generator
  - grad_norm_discriminator

lr_scheduler:
  type: ExponentialLR
  args:
    gamma: 0.998

trainer:
  epochs: 1000
  save_dir: saved/
  save_period: 20
  verbosity: 2
  visualize: "wandb"
  wandb_project: nv_project
  grad_norm_clip: 10
  grad_max_abs: 1000
  mixed_precision: true
  len_epoch: 100
resume: null
device: cuda
hydra:
  run:
    dir: .
test_settings:
  sample_rate: 22050
  out_dir: "final_results"
  mel_dir: null
  audio_dir: "test_data"